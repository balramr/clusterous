## Spark Environment

```shell

clusterous create spark-cluster.yml
```

It will give you a spark cluster up and running with an IPython notebook to interact with.

You can specify the number and type of nodes in "spark-cluster.yml" file.

A trivial Python example has been added to the default IPython notebook folder.

### Configuration diagram
![](misc/clusterous-spark-v2.png)
